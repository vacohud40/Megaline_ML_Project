{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Carrier Plan Prediction\n",
    "\n",
    "**Project Description:**\n",
    "\n",
    "Mobile carrier Megaline has observed that many subscribers are still using legacy plans. They aim to develop a machine learning model that analyzes subscriber behavior and recommends one of their newer plans: Smart or Ultra. This model will be trained on data from subscribers who have already transitioned to the new plans.\n",
    "\n",
    "**Analysis Goal:**\n",
    "\n",
    "The goal of this project is to build a classification model with the highest possible accuracy (threshold of 0.75) to predict whether a subscriber should be recommended the \"Smart\" or \"Ultra\" plan, based on their usage patterns. We will investigate different classification models and tune their hyperparameters to achieve optimal performance, and then assess the final model's accuracy on a separate test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Importing the necessary libraries \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "0    2229\n",
      "1     985\n",
      "Name: is_ultra, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Opening and looking through the data file.\n",
    "df = pd.read_csv('/datasets/users_behavior.csv')\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df['is_ultra'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The target variable `is_ultra` exhibits a significant class imbalance, with approximately 69.4% of users on the \"Smart\" plan (0) and 30.6% on the \"Ultra\" plan (1). This imbalance should be addressed during model training and evaluation to prevent biased results and ensure adequate performance on both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 1928\n",
      "Validation set size: 643\n",
      "Test set size: 643\n"
     ]
    }
   ],
   "source": [
    "#  Splitting the source data into a training set, a validation set, and a test set.\n",
    "features = df.drop('is_ultra', axis=1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=12345\n",
    ")\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_train, target_train, test_size=0.25, random_state=12345\n",
    ") # 0.25 of train equals to 0.2 of total data.\n",
    "\n",
    "print(f\"Train set size: {len(features_train)}\")\n",
    "print(f\"Validation set size: {len(features_valid)}\")\n",
    "print(f\"Test set size: {len(features_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The dataset has been successfully split into training, validation, and test sets. The training set contains 1928 samples, while both the validation and test sets contain 643 samples each. This distribution ensures a substantial training dataset for model learning, while reserving equally sized validation and test sets for hyperparameter tuning and final performance evaluation, respectively. The validation set represents 20% of the original dataset, and the test set represents 20% of the original dataset, as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7744945567651633, Max Depth: 7\n"
     ]
    }
   ],
   "source": [
    "# Investigating the quality of different models by changing hyperparameters.\n",
    "\n",
    "best_model = None\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "\n",
    "# Decision Tree\n",
    "for depth in range(1, 11):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    result = model.score(features_valid, target_valid)\n",
    "    if result > best_result:\n",
    "        best_model = model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {best_result}, Max Depth: {best_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Performance:** The Decision Tree model achieved an accuracy of approximately 77.45% on the validation dataset, with an optimal `max_depth` of 7. This indicates that a tree with a maximum depth of 7 provided the best balance between model complexity and generalization performance, preventing overfitting while capturing relevant patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7978227060653188, Estimators: 50, Max Depth: 10\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "best_forest_model = None\n",
    "best_forest_result = 0\n",
    "best_est = 0\n",
    "best_forest_depth = 0\n",
    "\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range(1, 11):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        result = model.score(features_valid, target_valid)\n",
    "        if result > best_forest_result:\n",
    "            best_forest_model = model\n",
    "            best_forest_result = result\n",
    "            best_est = est\n",
    "            best_forest_depth = depth\n",
    "\n",
    "print(f\"Random Forest Accuracy: {best_forest_result}, Estimators: {best_est}, Max Depth: {best_forest_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Performance:** The Random Forest model demonstrated an accuracy of approximately 79.78% on the validation dataset, achieving the highest performance among the tested models. This optimal result was obtained with 50 estimators (`n_estimators`) and a maximum depth of 10 (`max_depth`). This configuration suggests that a larger ensemble of trees with a greater depth effectively captured complex relationships within the data, leading to improved predictive accuracy compared to the Decision Tree and Logistic Regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7293934681181959\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logistic_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "logistic_model.fit(features_train, target_train)\n",
    "logistic_result = logistic_model.score(features_valid, target_valid)\n",
    "print(f\"Logistic Regression Accuracy: {logistic_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Performance:** The Logistic Regression model achieved an accuracy of approximately 72.94% on the validation dataset. This suggests that while Logistic Regression can provide a reasonable baseline, it performed less effectively than the Decision Tree and Random Forest models in capturing the complexities of the data. This indicates that the relationships between the features and the target variable might be non-linear, which Logistic Regression, being a linear model, struggles to fully represent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest chosen as the final model.\n",
      "Test Accuracy: 0.7993779160186625\n"
     ]
    }
   ],
   "source": [
    "# Checking the quality of the model using the test set.\n",
    "\n",
    "if best_forest_result > best_result and best_forest_result > logistic_result:\n",
    "    final_model = best_forest_model\n",
    "    print(\"Random Forest chosen as the final model.\")\n",
    "elif best_result > best_forest_result and best_result > logistic_result:\n",
    "    final_model = best_model\n",
    "    print(\"Decision Tree chosen as the final model.\")\n",
    "else:\n",
    "    final_model = logistic_model\n",
    "    print(\"Logistic Regression chosen as the final model.\")\n",
    "    \n",
    "test_accuracy = final_model.score(features_test, target_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Model Performance:** The Random Forest model, selected based on its superior performance on the validation set, achieved a test accuracy of approximately 79.94%. This confirms the model's ability to generalize well to unseen data, meeting the project's accuracy threshold of 0.75 and demonstrating its effectiveness in predicting user plan preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier (most frequent) Accuracy: 0.6951788491446346\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check.\n",
    "\n",
    "#Checking if the model predicts the majority class when the data is not useful.\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "dummy_pred = dummy_clf.predict(features_test)\n",
    "dummy_accuracy = accuracy_score(target_test, dummy_pred)\n",
    "\n",
    "print(f\"Dummy Classifier (most frequent) Accuracy: {dummy_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy Classifier Baseline:** The Dummy Classifier, using the \"most frequent\" strategy, achieved an accuracy of approximately 69.52% on the test dataset. This baseline represents the accuracy we would expect if we simply predicted the majority class (\"Smart\" plan) for all users. The fact that our chosen Random Forest model achieved a test accuracy of approximately 79.94% demonstrates that it significantly outperforms this baseline, indicating that it has learned meaningful patterns from the data beyond simply predicting the most frequent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performs better than the dummy classifier.\n"
     ]
    }
   ],
   "source": [
    "# Comparing the dummy accuracy with the test accuracy of the model to see if the model is better than just predicting the majority class.\n",
    "if test_accuracy > dummy_accuracy:\n",
    "    print(\"The model performs better than the dummy classifier.\")\n",
    "else:\n",
    "    print(\"The model does not perform better than the dummy classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Validation:** The trained Random Forest model's test accuracy (approximately 79.94%) significantly exceeds the Dummy Classifier's baseline accuracy (approximately 69.52%). This confirms that the model has successfully learned meaningful patterns from the data and performs better than simply predicting the majority class, validating its effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "This project aimed to develop a classification model to predict user plan preferences (Smart or Ultra) for a mobile carrier, Megaline. Through data exploration, preprocessing, and model training, we successfully built a Random Forest classifier that achieved a test accuracy of approximately 79.94%. This performance surpasses the project's accuracy threshold of 0.75 and significantly outperforms a baseline Dummy Classifier, demonstrating the model's ability to learn meaningful patterns from user behavior data.\n",
    "\n",
    "The Random Forest model, with optimized hyperparameters (50 estimators and a maximum depth of 10), proved to be the most effective among the models tested, including Decision Tree and Logistic Regression. The model's generalization ability was validated by its consistent performance on the unseen test dataset.\n",
    "\n",
    "The analysis highlighted the importance of addressing class imbalance, which was present in the target variable. Future improvements could explore techniques like oversampling or undersampling to further enhance the model's performance, particularly in predicting the minority \"Ultra\" plan class. \n",
    "\n",
    "Overall, the developed Random Forest model provides a valuable tool for Megaline to analyze subscriber behavior and recommend appropriate plans, potentially leading to increased customer satisfaction and revenue."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 848,
    "start_time": "2025-03-12T02:14:41.783Z"
   },
   {
    "duration": 617,
    "start_time": "2025-03-12T02:15:40.572Z"
   },
   {
    "duration": 71,
    "start_time": "2025-03-12T02:17:32.189Z"
   },
   {
    "duration": 73,
    "start_time": "2025-03-12T02:20:21.172Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-12T02:21:41.736Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-12T02:22:29.460Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-12T02:22:34.492Z"
   },
   {
    "duration": 770,
    "start_time": "2025-03-12T02:31:09.557Z"
   },
   {
    "duration": 624,
    "start_time": "2025-03-12T02:32:23.528Z"
   },
   {
    "duration": 1525,
    "start_time": "2025-03-12T03:42:51.905Z"
   },
   {
    "duration": 1386,
    "start_time": "2025-03-12T03:42:53.433Z"
   },
   {
    "duration": 782,
    "start_time": "2025-03-13T01:15:45.146Z"
   },
   {
    "duration": 578,
    "start_time": "2025-03-13T01:15:51.827Z"
   },
   {
    "duration": 59,
    "start_time": "2025-03-13T01:21:27.261Z"
   },
   {
    "duration": 63,
    "start_time": "2025-03-13T01:23:09.357Z"
   },
   {
    "duration": 806,
    "start_time": "2025-03-13T18:46:53.289Z"
   },
   {
    "duration": 648,
    "start_time": "2025-03-13T18:46:54.097Z"
   },
   {
    "duration": 916,
    "start_time": "2025-03-14T00:56:19.622Z"
   },
   {
    "duration": 41,
    "start_time": "2025-03-14T00:56:25.061Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-14T01:06:59.726Z"
   },
   {
    "duration": 56,
    "start_time": "2025-03-14T01:13:45.190Z"
   },
   {
    "duration": 3003,
    "start_time": "2025-03-14T01:16:50.667Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-14T01:19:42.516Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-14T01:23:58.504Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-14T01:27:41.627Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-14T01:30:31.268Z"
   },
   {
    "duration": 799,
    "start_time": "2025-03-14T01:36:09.581Z"
   },
   {
    "duration": 27,
    "start_time": "2025-03-14T01:36:14.228Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-14T01:37:40.576Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-14T01:38:00.816Z"
   },
   {
    "duration": 56,
    "start_time": "2025-03-14T01:38:08.882Z"
   },
   {
    "duration": 2846,
    "start_time": "2025-03-14T01:38:18.488Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-14T01:38:24.903Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-14T01:38:29.130Z"
   },
   {
    "duration": 830,
    "start_time": "2025-03-14T01:38:51.128Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-14T01:38:51.962Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-14T01:38:51.999Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-14T01:38:52.007Z"
   },
   {
    "duration": 86,
    "start_time": "2025-03-14T01:38:52.018Z"
   },
   {
    "duration": 2913,
    "start_time": "2025-03-14T01:38:52.106Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-14T01:38:55.021Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-14T01:38:55.034Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-14T01:38:55.045Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-14T01:38:55.070Z"
   },
   {
    "duration": 745,
    "start_time": "2025-03-14T14:34:56.140Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-14T14:34:56.887Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-14T14:34:56.924Z"
   },
   {
    "duration": 8,
    "start_time": "2025-03-14T14:34:56.932Z"
   },
   {
    "duration": 79,
    "start_time": "2025-03-14T14:34:56.941Z"
   },
   {
    "duration": 3416,
    "start_time": "2025-03-14T14:34:57.023Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-14T14:35:00.441Z"
   },
   {
    "duration": 10,
    "start_time": "2025-03-14T14:35:00.453Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-14T14:35:00.465Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-14T14:35:00.473Z"
   },
   {
    "duration": 2,
    "start_time": "2025-03-14T14:35:54.432Z"
   },
   {
    "duration": 24,
    "start_time": "2025-03-14T14:35:54.436Z"
   },
   {
    "duration": 6,
    "start_time": "2025-03-14T14:35:54.462Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-14T14:35:54.470Z"
   },
   {
    "duration": 70,
    "start_time": "2025-03-14T14:35:54.479Z"
   },
   {
    "duration": 3311,
    "start_time": "2025-03-14T14:35:54.550Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-14T14:35:57.863Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-14T14:35:57.876Z"
   },
   {
    "duration": 22,
    "start_time": "2025-03-14T14:35:57.889Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-14T14:35:57.913Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-14T14:45:35.644Z"
   }
  ],
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
